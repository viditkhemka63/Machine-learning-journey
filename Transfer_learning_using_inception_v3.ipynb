{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer learning using inception_v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viditkhemka63/Machine-learning-journey/blob/master/Transfer_learning_using_inception_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30e0695f-c557-4b77-a678-663e99810ea6"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "    \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-09 07:11:58--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 66.102.1.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|66.102.1.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  65.6MB/s    in 1.3s    \n",
            "\n",
            "2019-07-09 07:11:59 (65.6 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0709 07:12:00.926676 140618574288768 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe3f8aa6-7a67-4dfe-aa76-f0d10a6fddd0"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer( 'mixed7' )\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "690da5f1-5b40-4ed6-9fbf-77952123fe7a"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense( 1024, activation = 'relu' )(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout( 0.2 )(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1,  activation = 'sigmoid' )(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0709 07:19:41.527462 140618574288768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "03c424a7-f6ef-4ff4-ad02-c681e1f296ab"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-09 07:21:24--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.167.128, 2a00:1450:400c:c0a::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.167.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "\r/tmp/horse-or-human   0%[                    ]       0  --.-KB/s               \r/tmp/horse-or-human   5%[>                   ]   7.26M  36.3MB/s               \r/tmp/horse-or-human  36%[======>             ]  52.37M   131MB/s               \r/tmp/horse-or-human  69%[============>       ]  98.59M   164MB/s               \r/tmp/horse-or-human  98%[==================> ] 139.94M   175MB/s               \r/tmp/horse-or-human 100%[===================>] 142.65M   176MB/s    in 0.8s    \n",
            "\n",
            "2019-07-09 07:21:25 (176 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-07-09 07:21:28--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.167.128, 2a00:1450:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.167.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-07-09 07:21:28 (102 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ca616530-0f73-4870-81da-cfbcf8b88c7c"
      },
      "source": [
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "61801218-bbc0-43f4-ce07-38a635bfc124"
      },
      "source": [
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef980c18-c329-42a7-9bf0-32dc878b8337"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 34s - loss: 0.2165 - acc: 0.9155 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "100/100 - 29s - loss: 0.0687 - acc: 0.9745 - val_loss: 0.0499 - val_acc: 0.9848\n",
            "Epoch 3/100\n",
            "100/100 - 29s - loss: 0.0727 - acc: 0.9752 - val_loss: 0.0803 - val_acc: 0.9808\n",
            "Epoch 4/100\n",
            "100/100 - 29s - loss: 0.0393 - acc: 0.9853 - val_loss: 0.3210 - val_acc: 0.9605\n",
            "Epoch 5/100\n",
            "100/100 - 28s - loss: 0.0525 - acc: 0.9848 - val_loss: 0.0956 - val_acc: 0.9767\n",
            "Epoch 6/100\n",
            "100/100 - 28s - loss: 0.0186 - acc: 0.9909 - val_loss: 0.5157 - val_acc: 0.9524\n",
            "Epoch 7/100\n",
            "100/100 - 28s - loss: 0.0283 - acc: 0.9899 - val_loss: 0.1640 - val_acc: 0.9737\n",
            "Epoch 8/100\n",
            "100/100 - 28s - loss: 0.0420 - acc: 0.9873 - val_loss: 0.1640 - val_acc: 0.9838\n",
            "Epoch 9/100\n",
            "100/100 - 28s - loss: 0.0228 - acc: 0.9919 - val_loss: 0.1229 - val_acc: 0.9889\n",
            "Epoch 10/100\n",
            "100/100 - 28s - loss: 0.0216 - acc: 0.9934 - val_loss: 0.1020 - val_acc: 0.9889\n",
            "Epoch 11/100\n",
            "100/100 - 28s - loss: 0.0153 - acc: 0.9955 - val_loss: 0.3219 - val_acc: 0.9595\n",
            "Epoch 12/100\n",
            "100/100 - 28s - loss: 0.0073 - acc: 0.9975 - val_loss: 0.1406 - val_acc: 0.9879\n",
            "Epoch 13/100\n",
            "100/100 - 28s - loss: 0.0274 - acc: 0.9924 - val_loss: 0.2024 - val_acc: 0.9696\n",
            "Epoch 14/100\n",
            "100/100 - 27s - loss: 0.0278 - acc: 0.9970 - val_loss: 0.1518 - val_acc: 0.9838\n",
            "Epoch 15/100\n",
            "100/100 - 29s - loss: 0.0231 - acc: 0.9929 - val_loss: 0.0978 - val_acc: 0.9889\n",
            "Epoch 16/100\n",
            "100/100 - 29s - loss: 0.0135 - acc: 0.9930 - val_loss: 0.8728 - val_acc: 0.9443\n",
            "Epoch 17/100\n",
            "100/100 - 28s - loss: 0.0340 - acc: 0.9898 - val_loss: 0.4968 - val_acc: 0.9605\n",
            "Epoch 18/100\n",
            "100/100 - 28s - loss: 0.0234 - acc: 0.9959 - val_loss: 0.7737 - val_acc: 0.9534\n",
            "Epoch 19/100\n",
            "100/100 - 28s - loss: 0.0123 - acc: 0.9959 - val_loss: 1.0651 - val_acc: 0.9372\n",
            "Epoch 20/100\n",
            "100/100 - 28s - loss: 0.0143 - acc: 0.9954 - val_loss: 0.3392 - val_acc: 0.9686\n",
            "Epoch 21/100\n",
            "100/100 - 28s - loss: 0.0109 - acc: 0.9975 - val_loss: 0.2727 - val_acc: 0.9717\n",
            "Epoch 22/100\n",
            "100/100 - 28s - loss: 0.0173 - acc: 0.9940 - val_loss: 0.6384 - val_acc: 0.9575\n",
            "Epoch 23/100\n",
            "100/100 - 28s - loss: 0.0262 - acc: 0.9924 - val_loss: 0.5656 - val_acc: 0.9615\n",
            "Epoch 24/100\n",
            "100/100 - 28s - loss: 0.0200 - acc: 0.9945 - val_loss: 0.4601 - val_acc: 0.9676\n",
            "Epoch 25/100\n",
            "100/100 - 29s - loss: 0.0245 - acc: 0.9954 - val_loss: 0.3754 - val_acc: 0.9656\n",
            "Epoch 26/100\n",
            "100/100 - 29s - loss: 0.0378 - acc: 0.9924 - val_loss: 0.3362 - val_acc: 0.9696\n",
            "Epoch 27/100\n",
            "100/100 - 28s - loss: 0.0249 - acc: 0.9954 - val_loss: 0.4051 - val_acc: 0.9727\n",
            "Epoch 28/100\n",
            "100/100 - 30s - loss: 0.0281 - acc: 0.9939 - val_loss: 0.8445 - val_acc: 0.9494\n",
            "Epoch 29/100\n",
            "100/100 - 29s - loss: 0.0264 - acc: 0.9940 - val_loss: 0.6052 - val_acc: 0.9585\n",
            "Epoch 30/100\n",
            "100/100 - 29s - loss: 0.0375 - acc: 0.9929 - val_loss: 0.2849 - val_acc: 0.9767\n",
            "Epoch 31/100\n",
            "100/100 - 28s - loss: 0.0034 - acc: 0.9985 - val_loss: 0.5328 - val_acc: 0.9666\n",
            "Epoch 32/100\n",
            "100/100 - 28s - loss: 0.0199 - acc: 0.9934 - val_loss: 0.4099 - val_acc: 0.9676\n",
            "Epoch 33/100\n",
            "100/100 - 28s - loss: 0.0280 - acc: 0.9930 - val_loss: 0.8329 - val_acc: 0.9524\n",
            "Epoch 34/100\n",
            "100/100 - 28s - loss: 0.0040 - acc: 0.9985 - val_loss: 0.8668 - val_acc: 0.9504\n",
            "Epoch 35/100\n",
            "100/100 - 28s - loss: 0.0190 - acc: 0.9954 - val_loss: 0.9084 - val_acc: 0.9474\n",
            "Epoch 36/100\n",
            "100/100 - 27s - loss: 0.0148 - acc: 0.9975 - val_loss: 0.8170 - val_acc: 0.9514\n",
            "Epoch 37/100\n",
            "100/100 - 28s - loss: 0.0026 - acc: 0.9990 - val_loss: 0.7952 - val_acc: 0.9534\n",
            "Epoch 38/100\n",
            "100/100 - 28s - loss: 0.0152 - acc: 0.9970 - val_loss: 0.6940 - val_acc: 0.9575\n",
            "Epoch 39/100\n",
            "100/100 - 29s - loss: 0.0256 - acc: 0.9959 - val_loss: 0.7768 - val_acc: 0.9524\n",
            "Epoch 40/100\n",
            "100/100 - 27s - loss: 0.0057 - acc: 0.9975 - val_loss: 1.0782 - val_acc: 0.9484\n",
            "Epoch 41/100\n",
            "100/100 - 29s - loss: 0.0166 - acc: 0.9965 - val_loss: 0.4694 - val_acc: 0.9656\n",
            "Epoch 42/100\n",
            "100/100 - 29s - loss: 0.0067 - acc: 0.9970 - val_loss: 1.0958 - val_acc: 0.9453\n",
            "Epoch 43/100\n",
            "100/100 - 28s - loss: 0.0168 - acc: 0.9959 - val_loss: 0.9644 - val_acc: 0.9504\n",
            "Epoch 44/100\n",
            "100/100 - 28s - loss: 0.0082 - acc: 0.9980 - val_loss: 0.5425 - val_acc: 0.9717\n",
            "Epoch 45/100\n",
            "100/100 - 28s - loss: 0.0202 - acc: 0.9970 - val_loss: 1.2144 - val_acc: 0.9403\n",
            "Epoch 46/100\n",
            "100/100 - 28s - loss: 0.0114 - acc: 0.9975 - val_loss: 0.4965 - val_acc: 0.9686\n",
            "Epoch 47/100\n",
            "100/100 - 28s - loss: 0.0074 - acc: 0.9980 - val_loss: 0.5479 - val_acc: 0.9636\n",
            "Epoch 48/100\n",
            "100/100 - 28s - loss: 0.0113 - acc: 0.9980 - val_loss: 1.0056 - val_acc: 0.9464\n",
            "Epoch 49/100\n",
            "100/100 - 28s - loss: 0.0105 - acc: 0.9980 - val_loss: 0.5572 - val_acc: 0.9686\n",
            "Epoch 50/100\n",
            "100/100 - 28s - loss: 0.0218 - acc: 0.9960 - val_loss: 0.9147 - val_acc: 0.9565\n",
            "Epoch 51/100\n",
            "100/100 - 28s - loss: 0.0240 - acc: 0.9939 - val_loss: 0.7463 - val_acc: 0.9565\n",
            "Epoch 52/100\n",
            "100/100 - 28s - loss: 0.0216 - acc: 0.9939 - val_loss: 1.1019 - val_acc: 0.9484\n",
            "Epoch 53/100\n",
            "100/100 - 28s - loss: 0.0109 - acc: 0.9975 - val_loss: 0.9308 - val_acc: 0.9504\n",
            "Epoch 54/100\n",
            "100/100 - 30s - loss: 0.0098 - acc: 0.9975 - val_loss: 0.8402 - val_acc: 0.9514\n",
            "Epoch 55/100\n",
            "100/100 - 29s - loss: 0.0111 - acc: 0.9980 - val_loss: 0.9846 - val_acc: 0.9484\n",
            "Epoch 56/100\n",
            "100/100 - 29s - loss: 0.0213 - acc: 0.9970 - val_loss: 1.1149 - val_acc: 0.9494\n",
            "Epoch 57/100\n",
            "100/100 - 28s - loss: 0.0278 - acc: 0.9944 - val_loss: 1.4856 - val_acc: 0.9372\n",
            "Epoch 58/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 28s - loss: 4.8142e-04 - acc: 1.0000 - val_loss: 1.2895 - val_acc: 0.9423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "69f39073-15fc-4a23-9989-2fec0fe7bc58"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJIp+CCF0kSj6IYTQRaLohxBCF/kJhfjVLNlMKoIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}